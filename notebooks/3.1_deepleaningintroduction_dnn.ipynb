{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marcoteran/deeplearning/blob/master/notebooks/3.1_deepleaningintroduction_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marcoteran/deeplearning/blob/master/notebooks/3.1_deepleaningintroduction_dnn.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Abrir en Kaggle\" title=\"Abrir y ejecutar en Kaggle\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de c칩digo\n",
    "# Sesi칩n 07: Introducci칩n al Aprendizaje profundo\n",
    "## Deep Learning y series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran **E-mail:** marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar librer칤as importantes\n",
    "\n",
    "Definimos primero unas librer칤as y funciones que vamos a usar a durante la sesi칩n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set()  # for plot styling\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN\n",
    "from IPython.display import HTML\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurona artificial\n",
    "\n",
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/ArtificialNeuronModel_english.png/600px-ArtificialNeuronModel_english.png\" >\n",
    "\n",
    "* El perceptr칩n es un algoritmo de clasificaci칩n que genera una predicci칩n para una entrada $(x)$ de la siguiente manera:\n",
    "$$\\textrm{Predicci칩n}(x)=\\begin{cases}\n",
    "C_{1} & \\mbox{si }f(x)\\ge \\theta\\\\\n",
    "C_{2} & \\mbox{si }f(x)<\\theta\n",
    "\\end{cases}$$\n",
    "\n",
    "* De igual forma, $f(x)$ est치 definida como una suma ponderada sobre los elementos de la entrada:\n",
    "$$\n",
    "f(x) = w_0 + \\sum_{i=1}^{n} {w_i x_i}\n",
    "$$\n",
    "d칩nde $x$ corresponde a la entrada, $w$ corresponde a los pesos que se multiplican por la entrada $x$ y $w_0$ al sesgo.\n",
    "\n",
    "* Para poder generar $\\textrm{Predicci칩n}(x)$, se toma la salida de $f(x)$ y se le aplica una **funci칩n de activaci칩n** $\\varphi$. As칤 la salida del perceptr칩n es de la siguiente forma:\n",
    "$$\n",
    "y = \\varphi(w_0 + \\sum_{i=1}^{n} {w_i x_i})\n",
    "$$\n",
    "\n",
    "* Es com칰n encontrar en la literatura que se mencione que una neurona se activ칩, si su valor de la salida $y$ super칩 el umbral $\\theta$ definido para la neurona.\n",
    "\n",
    "**쮺칩mo escoger $\\varphi$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci칩n de activaci칩n de paso\n",
    "\n",
    "El caso m치s sencillo se conoce como la funci칩n de activaci칩n de paso. La funci칩n de activaci칩n de paso se define de la siguiente manera:\n",
    "\n",
    "$$\\textrm{H}(x)=\\begin{cases}\n",
    "0 & \\mbox{si }x\\ge \\theta\\\\\n",
    "1 & \\mbox{si }x<\\theta\n",
    "\\end{cases}$$\n",
    "\n",
    "La cual observamos a continuaci칩n\n",
    "\n",
    "<img src=\"https://c.mql5.com/2/4/act1.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci칩n de activaci칩n log칤stica\n",
    "\n",
    "La funci칩n de activaci칩n log칤stica est치 basada en la funci칩n sigmoide $\\sigma$. La funci칩n sigmo칤de para cualquier valor $z$ se define de la siguiente manera:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 - e^{-z}}$$\n",
    "\n",
    "<img width= 300 src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/SigmoidFunction.png/400px-SigmoidFunction.png\" align=\"middle\">\n",
    "\n",
    "C칩mo se puede observar en la imagen, la funci칩n sigmoide genera valores entre $0$ y $1$. A diferencia de la funci칩n de activaci칩n de paso, la sigmoide genera una transici칩n entre $0$ y $1$. La salida del perceptr칩n queda definida de la siguiente manera:\n",
    "\n",
    "$$\n",
    "y = \\sigma(w_0 + \\sum_{i=1}^{n} {w_i x_i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1: El Hello World del Deep Learning con Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en cada primera aplicaci칩n, deber칤as empezar con algo super simple que muestre el andamiaje general de c칩mo funciona tu c칩digo. \n",
    "\n",
    "En el caso de la creaci칩n de redes neuronales, la muestra que me gusta usar es una en la que se aprende la relaci칩n entre dos n칰meros. As칤, por ejemplo, si estuvieras escribiendo c칩digo para una funci칩n como esta, ya conoces las \"reglas\" - \n",
    "\n",
    "```\n",
    "float hw_function(float x){\n",
    "    float y = (2 * x) - 1;\n",
    "    return y;\n",
    "}\n",
    "```\n",
    "Entonces, 쯖칩mo entrenar칤as a una red neuronal para hacer la tarea equivalente? 춰Usando datos! Aliment치ndola con un conjunto de Xs, y un conjunto de Ys, deber칤a ser capaz de averiguar la relaci칩n entre ellos. \n",
    "\n",
    "Obviamente, este es un paradigma muy diferente al que podr칤as estar acostumbrado, as칤 que vamos a repasarlo pieza por pieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir y compilar la red neuronal\n",
    "\n",
    "A continuaci칩n crearemos la red neuronal m치s simple posible. Tiene una capa, y esa capa tiene una neurona, y la forma de entrada a ella es s칩lo un valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora compilamos nuestra Red Neural. Cuando lo hacemos, tenemos que especificar 2 funciones, una funci칩n de p칠rdida y un optimizador.\n",
    "\n",
    "Si has visto muchas matem치ticas para el aprendizaje de la m치quina, aqu칤 es donde se utiliza normalmente, pero en este caso est치 bien encapsulado en funciones para ti. Pero lo que sucede aqu칤 - vamos a explicar...\n",
    "\n",
    "Sabemos que en nuestra funci칩n, la relaci칩n entre los n칰meros es y=2x-1. \n",
    "\n",
    "Cuando la computadora est치 tratando de \"aprender\" eso, hace una suposici칩n... tal vez y=10x+10. La funci칩n P칄RDIDA mide las respuestas adivinadas contra las respuestas correctas conocidas y mide qu칠 tan bien o qu칠 tan mal lo hizo.\n",
    "\n",
    "Luego usa la funci칩n OPTIMIZADOR para hacer otra suposici칩n. Bas치ndose en c칩mo fue la funci칩n de p칠rdida, intentar치 minimizar la p칠rdida. En ese punto, tal vez se le ocurra algo como y=5x+5, que, aunque sigue siendo bastante malo, est치 m치s cerca del resultado correcto (es decir, la p칠rdida es menor)\n",
    "\n",
    "Lo repetir치 para el n칰mero de EPOCHS que ver치 en breve. Pero primero, as칤 es como le decimos que use \"ERROR CUADRADO MEDIO\" para la p칠rdida y \"DESCENSO GRADIANTE EST칍STICO\" para el optimizador. No necesitas entender las matem치ticas para esto todav칤a, 춰pero puedes ver que funcionan! :)\n",
    "\n",
    "Con el tiempo aprender치s las diferentes y apropiadas funciones de p칠rdida y optimizador para diferentes escenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proveyendo los datos\n",
    "\n",
    "A continuaci칩n, alimentaremos algunos datos. En este caso estamos tomando 6 x y 6ys. Puedes ver que la relaci칩n entre estos es que y=2x-1, as칤 que donde x = -1, y=-3 etc. etc. \n",
    "\n",
    "Una biblioteca de pit칩n llamada 'Numpy' proporciona un mont칩n de estructuras de datos de tipo matriz que son una forma est치ndar de hecho de hacerlo. Declaramos que queremos usarlas especificando los valores como un np.array[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando la Red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de entrenamiento de la red neuronal, donde \"aprende\" la relaci칩n entre los X y los Y est치 en la llamada **model.fit**. Aqu칤 es donde pasar치 por el bucle del que hablamos anteriormente, haciendo una suposici칩n, midiendo lo bueno o lo malo que es (tambi칠n conocido como la p칠rdida), usando el opimizador para hacer otra suposici칩n, etc. Lo har치 para el n칰mero de 칠pocas que especifiques. Cuando ejecute este c칩digo, ver치 la p칠rdida en el lado derecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, ahora tienes un modelo que ha sido entrenado para aprender la relaci칩n entre X e Y. Puedes usar el m칠todo **model.predict** para que descubra el Y de un X previamente desconocido. As칤, por ejemplo, si X = 10, 쯤u칠 crees que ser치 Y? Adivina antes de ejecutar este c칩digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podr칤as haber pensado en el 19, 쯨erdad? Pero termin칩 siendo un poco menos. 쯇or qu칠 crees que es as칤? \n",
    "\n",
    "Recuerda que las redes neuronales tratan con probabilidades, as칤 que dados los datos con los que alimentamos a los NN, calcul칩 que hay una probabilidad muy alta de que la relaci칩n entre X e Y sea Y=2X-1, pero con s칩lo 6 puntos de datos no podemos saberlo con seguridad. Como resultado, el resultado para 10 es muy cercano a 19, pero no necesariamente 19. \n",
    "\n",
    "A medida que trabajes con redes neuronales, ver치s que este patr칩n se repite. Casi siempre tratar치 con probabilidades, no certezas, y har치 un poco de codificaci칩n para averiguar cu치l es el resultado basado en las probabilidades, particularmente cuando se trata de la clasificaci칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Clasificador de digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# helps us to represent our data as lists easily and quickly\n",
    "import numpy as np\n",
    "# framework for defining a neural network as a set of Sequential layers\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos del MNIST est치n disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas as칤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[8], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver la etiqueta\n",
    "print(y_train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = x_train[0:100,:]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = x_train[:,7:-7,7:-7]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado de datos de entrada en una red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train/=255\n",
    "x_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rs = x_train.reshape(60000,784)\n",
    "x_test_rs = x_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_rs.shape)\n",
    "print(x_test_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definici칩n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuraci칩n del proceso de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_rs, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci칩n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "test_loss, test_acc = model.evaluate(x_test_rs, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generaci칩n de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[11], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(predictions[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 3: Redes neuronales en Keras: Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a un escenario en el que podemos reconocer diferentes prendas de vestir, entrenadas a partir de un conjunto de datos que contiene 10 tipos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos del MNIST de la moda est치n disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas as칤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a load_data en este objeto le dar치 dos conjuntos de dos listas, estos ser치n los valores de entrenamiento y prueba para los gr치ficos que contienen las prendas de vestir y sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de datos\n",
    "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쮺칩mo son estos valores? Imprimamos una imagen de entrenamiento, y una etiqueta de entrenamiento para ver... Experimentemos con diferentes 칤ndices en la matriz. Por ejemplo, mira tambi칠n el 칤ndice 42... que es una bota diferente a la del 칤ndice 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar치n que todos los valores del n칰mero est치n entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es m치s f치cil si tratamos todos los valores entre 0 y 1, un proceso llamado '**normalizar**'... y afortunadamente en Python es f치cil normalizar una lista como esta sin hacer un bucle. Lo haces as칤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "training_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se preguntar치n por qu칠 hay dos grupos... entrenamiento y pruebas... Recuerdan que hablamos de esto en la introducci칩n? La idea es tener un conjunto de datos para el entrenamiento, y luego otro conjunto de datos... que el modelo a칰n no ha visto... para ver lo bueno que ser칤a para clasificar los valores. Despu칠s de todo, cuando termines, 춰vas a querer probarlo con datos que no hab칤a visto antes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_images.shape: \", training_images.shape)\n",
    "print(\"len(train_labels): \", len(training_labels))\n",
    "print(\"test_images.shape: \", test_images.shape)\n",
    "print(\"len(test_labels): \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i in range(50):\n",
    "    plt.subplot(10, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(training_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[training_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora dise침emos el modelo. Hay bastantes conceptos nuevos aqu칤, pero no te preocupes, les coger치s el tranquillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
    "\n",
    "**Flatten**: Recuerdas antes cuando nuestras im치genes eran un cuadrado, cuando las imprimiste? Flatten s칩lo toma ese cuadrado y lo convierte en un conjunto de una dimensi칩n.\n",
    "\n",
    "**Dense**: A침ade una capa de neuronas\n",
    "\n",
    "Cada capa de neuronas necesita una funci칩n de activaci칩n para decirles qu칠 hacer. Hay muchas opciones, pero por ahora s칩lo 칰salas. \n",
    "\n",
    "**Relu** significa efectivamente \"Si X>0 devuelve X, si no devuelve 0\" -- as칤 que lo que hace es pasar s칩lo valores 0 o mayores a la siguiente capa de la red.\n",
    "\n",
    "**Softmax** toma un conjunto de valores, y efectivamente escoge el m치s grande, as칤 que, por ejemplo, si la salida de la 칰ltima capa se ve como [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], te salva de pescar a trav칠s de ella buscando el valor m치s grande, y la convierte en [0,0,0,0,1,0,0,0,0,0] -- 춰El objetivo es salvar un mont칩n de codificaci칩n!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar el modelo\n",
    "\n",
    "Lo siguiente que hay que hacer, ahora que el modelo est치 definido, es construirlo realmente. Esto se hace compil치ndolo con una funci칩n de optimizaci칩n y p칠rdida como antes -- y luego lo entrena llamando a **model.fit** pidi칠ndole que ajuste los datos de su entrenamiento a sus etiquetas de entrenamiento -- es decir, que averig칲e la relaci칩n entre los datos de entrenamiento y sus etiquetas reales, de modo que en el futuro si tiene datos que se parecen a los datos de entrenamiento, entonces puede hacer una predicci칩n de c칩mo se ver칤an esos datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=[('accuracy')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que haya terminado el entrenamiento... deber칤as ver un valor de precisi칩n al final de la 칰ltima 칠poca. Podr칤a parecer algo como 0,9098. Esto te dice que tu red neural tiene una precisi칩n del 91% en la clasificaci칩n de los datos de entrenamiento. Es decir, calcul칩 una coincidencia de patr칩n entre la imagen y las etiquetas que funcion칩 el 91% de las veces. No es genial, pero no est치 mal considerando que s칩lo fue entrenado durante 5 칠pocas y se hizo bastante r치pido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쯇ero c칩mo funcionar칤a con datos no vistos? Por eso tenemos las im치genes de prueba. Podemos llamar a model.evaluate, y pasar en los dos conjuntos, y se informar치 de la p칠rdida para cada uno. Vamos a intentarlo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci칩n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para m칤, eso arroj칩 una precisi칩n de alrededor de 0,8838, lo que significa que fue de alrededor del 88% de exactitud. Como era de esperar, probablemente no le ir칤a tan bien con datos no vistos como con los datos en los que fue entrenado.  A medida que avance en este curso, ver치 formas de mejorarlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generaci칩n de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    " \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    " \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]),\n",
    "                                         color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#007700\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted label, and the true label\n",
    "# Color correct predictions in blue, incorrect predictions in red\n",
    "num_rows = 7\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejorar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=[('accuracy')])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels);\n",
    "print('\\nTest accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias generales\n",
    "\n",
    "- [Deep Learning en Wikipedia](https://es.wikipedia.org/wiki/Aprendizaje_profundo)\n",
    "- [Perceptr칩n](hhttps://es.wikipedia.org/wiki/Perceptr%C3%B3n)\n",
    "- [MLP](https://es.wikipedia.org/wiki/Perceptr%C3%B3n_multicapa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "춰Todo bien! 춰Es todo por hoy! 游"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
