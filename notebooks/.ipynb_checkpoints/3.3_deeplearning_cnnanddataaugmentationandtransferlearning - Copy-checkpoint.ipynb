{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<a href=\"https://colab.research.google.com/github/marcoteran/deeplearningmodule/blob/main/03_convolutionalneuralnetwork/03_convolutionalneuralnetwork.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de código\n",
    "# Deep Learning: Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Name:* Marco Teran\n",
    "*E-mail:* marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías importantes\n",
    "\n",
    "Empezamos con las importaciones estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#import mlutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "#importlib.reload(mlutils)\n",
    "#reload(mlutils) Python2\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set()  # for plot styling\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "%matplotlib inline\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN\n",
    "from IPython.display import HTML\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import pairwise_distances_argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué son las Redes convolucionales?\n",
    "\n",
    "Una **red neuronal convolucional** es un tipo de red neuronal artificial donde las neuronas corresponden a campos receptivos de una manera muy similar a las neuronas en la corteza visual primaria (V1) de un cerebro biológico. Este tipo de red es una variación de un perceptron multicapa, sin embargo, debido a que su aplicación es realizada en matrices bidimensionales, son muy efectivas para tareas de visión artificial, como en la clasificación y segmentación de imágenes, entre otras aplicaciones.\n",
    "![CNN](https://pedrofrodenas.github.io/assets/images/net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 1: clasificación de digitos MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial de Deep Learning con Keras para clasificar la base de datos MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Reshape\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de la base de datos MNIST\n",
    "Nota que al ser una base de datos tan popular ya existen scripts para descargar, descomprimir y formar el conjunto de datos de entreno y de test.\n",
    "En un caso real, hay que programar las funciones que se encarguen de la descarga, la importación, la unificación de las imagenes para que todas tengan el mismo tamaño, etc… Este paso normalmente es de los que ocupan más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos del MNIST están disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de:\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "Tamaño de:\n",
      "- Set de entranamiento:\t60000\n",
      "- Set de testeo:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "# Para descargar la base de datos MNIST\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"Tamaño de:\")\n",
    "print (train_images.shape)\n",
    "print (train_labels.shape)\n",
    "\n",
    "print(\"Tamaño de:\")\n",
    "print(\"- Set de entranamiento:\\t{}\".format(len(train_images)))\n",
    "print(\"- Set de testeo:\\t\\t{}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos MNIST ahora se ha cargado y consiste en 70,000 imágenes y números de clase para las imágenes. El conjunto de datos se divide en 3 subconjuntos. Uno se utiliza para entrenar la red, otro para testearla y otro para validar que el entreno se este realizando correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST contiene imagenes de números manuscritos que van desde el 0 hasta el 9, por tanto tenemos 10 clases a clasificar. Las imagenes se almacenan en un vector y las etiquetas en otro.\n",
    "Las etiquetas sirven para decirle a la red que número es una determinada imagen a la hora de entrenar. En la fase de test sirven para comprobar si la red neuronal ha clasificado bien un determinado número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "picnumber=25\n",
    "plt.imshow(train_images[picnumber], cmap=plt.cm.binary)\n",
    "# Ver la etiqueta\n",
    "print(train_labels[picnumber])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado de datos de entrada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Cambio a variables categoricas\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "print (train_images.shape)\n",
    "print (train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de una Red neuronal concolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras dispone de dos modos para construir una arquitectura de red, el sequential mode y el functional mode. En este tutorial usaremos el sequential mode que es el más simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el sequential mode se añaden capas de neuronas para formar la arquitectura neuronal. En la primera capa se deben especificar las dimensiones de los datos de entrada.\n",
    "En nuestro caso las imagenes se encuentran en un vector de una fila y 28*28 columnas. Una vez introducido el vector a la red hay que modificarlo para que se realice la convolución correctamente. Transformando el vector de [1, 784] a una matriz de [28, 28] que es la imagen que se puede visualizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos al constructor del modelo sequential\n",
    "model = Sequential()\n",
    "\n",
    "# Capa convolucional con funcion de activacion ReLU y max-pooling.\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar la estructura de la red\n",
    "Para comprobar la estructura de la red y el número de parámetros entrenables usamos la siguiente sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 832\n",
      "Trainable params: 832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de una red convolucional de más capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,096\n",
      "Trainable params: 52,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultima capa de la red, del tipo Dense. Nota que hay ``num_classes=10`` neuronas en esta capa. La clasificacion\n",
    "se hara comprobando que neurona obtiene a la salida un numero mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar la estructura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,346\n",
      "Trainable params: 62,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilación del modelo\n",
    "\n",
    "Se ha definido la estructura de la red neuronal convolucional, ahora hay que añadir el tipo de optimizador y las métricas que se van a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de Deep Learning generalmente son entrenados por un optimizador de descenso de gradiente estocástico. Hay muchas variaciones de descendencia de gradiente estocástica: ``Adam``, ``RMSProp``, ``Adagrad``, etc. Todas permiten establecer el learning rate.\n",
    "Cuando más pequeño sea este parámetro más tardará la red en entrenar y más precisión se obtendrá para el conjunto de datos de entreno. Hay que elegir un learning rate optimo para cada problema de Deep Learning. Si es muy pequeño la red aprenderá del ruido que hay en todas las imágenes y no de la función subyacente que relaciona las entradas y las salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se da este problema se obtiene una gran precisión para el conjunto de datos de entreno y disminuye para el de test porque la red se ha especializado en reconocer el conjunto de datos para el que ha sido entrenada y ha perdido la habilidad de generalizar para otros casos. Este problema se conoce como overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red\n",
    "\n",
    "Ahora que ya se ha definido la estructura de red, el optimizador, learning rate y metricas ya se puede entrenar la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mientras se va entrenando la red aparece la cantidad de épocas o epoch completadas. Una época o epoch es cuando la red ha visto todas las imagenes que contiene la base de datos. El número de epocas será otro hiperparámetro a elegir.\n",
    "* No es posible entrenar la red pasandole todas las imágenes a la vez porque la memoria RAM es un recurso limitado.\n",
    "* Por tanto se le pasan en grupos de un determinado número de imagenes conocido como batch size, cuento más grande sea este parámetro menos se tardará en completar el entreno. El batch size estrá limitado por la memoria RAM del computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 63s 102ms/step - loss: 0.9701 - accuracy: 0.7617\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 0.2640 - accuracy: 0.9221\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 71s 117ms/step - loss: 0.1891 - accuracy: 0.9442\n",
      "Epoch 4/5\n",
      "598/600 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9560"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels,\n",
    "          batch_size=100,\n",
    "          epochs=5,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la red\n",
    "Para ver si la red ha aprendido a clasificar bien los números manuscritos hay que comprobar la precisión que obtiene en el conjunto de datos de test. Para este conjunto no ha sido entrenada la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámtro ``test_acc`` es la precisión que ha obtenido la red para el conjunto de entreno.\n",
    "Ahora hay que comprobar si clasifica bien las imágenes del conjunto de test. Estas imágenes aún no las ha visto la red y no tiene información de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo\n",
    "Es útil gurdar un modelo que ha sido entrenado satisfactoriamente para su posterior uso. De esta manera no hay que entrenar de nuevo la red y se pueden realizar prediciones con el modelo guardado.\n",
    "\n",
    "* **NOTA:** Será necesario instalar el paquete h5py para poder guardar modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la carpeta donde se guarda el modelo y su nombre.\n",
    "# En este caso se guarda en el mismo directorio que contiene este script\n",
    "nombre_model = 'modelo.h5'\n",
    "\n",
    "# Guardamos el modelo y todos los pesos entrenados\n",
    "model.save(nombre_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 2: Conjunto de datos Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a un escenario en el que podemos reconocer diferentes prendas de vestir, entrenadas a partir de un conjunto de datos que contiene 10 tipos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Datos Fashion-MNIST](https://www.researchgate.net/profile/Greeshma_K_V/publication/340299295/figure/fig1/AS:875121904476163@1585656729996/Fashion-MNIST-Dataset-Images-with-Labels-and-Description-II-LITERATURE-REVIEW-In-image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Los datos del MNIST de la moda están disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a ``load_data`` en el objeto le dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo son estos valores? Imprimamos una imagen de entrenamiento, y una etiqueta de entrenamiento para ver... Experimentemos con diferentes índices en la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picnumber=42\n",
    "plt.imshow(train_images[picnumber], cmap=plt.cm.binary)\n",
    "# Ver la etiqueta\n",
    "print(train_labels[picnumber])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: modelo de base basado en el mismo modelo que el usado para el conjunto datos digits MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)    \n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]),\n",
    "               color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#00FF00\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28))\n",
    "test_images = test_images.reshape((10000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoramiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 7\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)     \n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Duplicando las neuronas de modelo base y añadiendo una capa densa de 64 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (7, 7), activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: modelo 3 cambiando al optimizador 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (7, 7), activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4: Buscando un modelo más complejo que usa capas BatchNormalization y Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una función que permita recrear una red convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', input_shape=(28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 5: Modelo anterior añadiendo más epochs (10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 6: Modelo anterior añadiendo más epochs (30 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=30)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 7: Modelo anterior añadiendo más epochs (30 epochs) y diferentes hiperparámetros al optimizador Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam (lr=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=30, callbacks=[reduce_lr])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28))\n",
    "test_images = test_images.reshape((10000, 28, 28))\n",
    "\n",
    "\n",
    "num_rows = 7\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)     \n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias generales\n",
    "\n",
    "- [Redes neuronales convolucionales](https://es.wikipedia.org/wiki/Redes_neuronales_convolucionales)\n",
    "- [Convolutional Neural Network (CNN) with TensorFlow](https://www.tensorflow.org/tutorials/images/cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<a href=\"https://colab.research.google.com/github/marcoteran/deeplearningmodule/blob/main/06_dataaugmentationandtransferlearning/06_dataaugmentationandtransferlearning.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de código\n",
    "# Deep Learning:  *Data Augmentation* y *Transfer Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Name:* Marco Teran\n",
    "- *E-mail:* marco.teran@usa.edu.co\n",
    "- [Website](http://marcoteran.github.io/), [Github](https://github.com/marcoteran), [LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "\n",
    "\n",
    "[**Slide del tema** ](https://github.com/marcoteran/deeplearningmodule/raw/main/05_deeplearning_generativeadversialnetworks.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías importantes\n",
    "\n",
    "Empezamos con las importaciones estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Data Augmentation: una de las técnicas más populares para mitigar el sobreajuste en los modelos de redes neuronales. En nuestro caso de estudio, esta técnica mejorará el modelo del capítulo anterior, que presentaba una precisión de 73.9 %, alcanzando una precisión de 80.1 %. Transfer Learning: permitirá mejorar aún más el modelo anterior.\n",
    "Primero presentaremos la técnica Feature Extraction usando una red preentrenada que nos llevará a una precisión de 90.4 % y, después, la técnica Fine-Tuning de una red preentrenada que nos llevará a una precisión de 93.1 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Cuantos menos datos tengamos, menos datos para entrenar y menos posibilidades tendremos de obtener predicciones precisas para datos que nuestro modelo aún no ha visto. Data Augmentation adopta el enfoque de generar más datos de entrenamiento a partir de nuestros datos disponibles. En el caso de imágenes, esto lo consigue aplicando una serie de transformaciones aleatorias a la imagen que producen nuevas imágenes de aspecto creíble. Esta idea simple, pero potente, ayuda a exponer el modelo a más aspectos de los datos y a generalizar mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones de imágenes\n",
    "\n",
    "Esta técnica es especialmente poderosa para datos de tipo imagen pero, a la vez, es muy simple, ya que aplica transformaciones sencillas (rotar, voltear...) a las imágenes para obtener nuevas imágenes plausibles, que podrían estar en el conjunto de datos original.\n",
    "No obstante, debe tenerse cuidado con la elección de las técnicas específicas de aumento de datos utilizadas. Hay que tener en cuenta el contexto del conjunto de datos de entrenamiento y el conocimiento del dominio del problema, para no generar imágenes que nunca podrían encontrarse en realidad ya que, de esta manera, estaríamos empeorando el entrenamiento.\n",
    "\n",
    "En Keras, esto se puede hacer de manera muy fácil mediante la configuración de una serie de transformaciones que se realizarán en las imágenes leídas por la instancia de ``ImageDataGenerator``.\n",
    "\n",
    "Para obtener información detallada sobre las transformaciones disponibles puede consultar la API preprocessing de Keras.\n",
    "\n",
    "Es importante resaltar que se realiza la transformación de manera onlinedurante el procesamiento, lo cual permite hacer el proceso automático mientras se realiza el entrenamiento sin necesidad de modificar los datos almacenados en disco. Así, el modelo ve una imagen generada aleatoriamente una sola vez. Evidentemente, estas transformaciones se podrían realizar previamente e incluirse en el conjunto de datos de entrenamiento. De esta manera, el preprocesado resultaría más rápido, puesto que no se realizarían las transformaciones en tiempo de ejecución; pero, en cambio, el espacio de almacenamiento y el tiempo de carga de los datos en memoria serían más elevados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuración de ImageGenerator\n",
    "\n",
    "Cogiendo de base el modelo presentado en el capítulo anterior, apliquemos la técnica Data Augmentation pasando nuevos argumentos al objeto ImageGenerator de los datos de entrenamiento. Hay varios parámetros; nosotros hemos elegido los siguientes para nuestro caso de estudio: \n",
    "```Python\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ``rotation_range`` es un valor en grados (0-180) que indica el rango dentrodel cual se pueden rotar imágenes al azar.\n",
    "* ``width_shift`` y height_shift son rangos (como una fracción del ancho y laaltura total) dentro de los cuales se pueden trasladar las imágenes alazar verticalmente u horizontalmente.\n",
    "* shear_range sirve para aplicar transformaciones de corte al azar.\n",
    "* ``zoom_range sirve para aplicar zoom aleatorio dentro de las imágenes\n",
    "* ``horizontal_flip`` sirve para voltear aleatoriamente la mitad de las imágeneshorizontalmente (en nuestro caso de estudio no tiene sentido voltearverticalmente las imágenes).\n",
    "* ``fill_mode`` es la estrategia utilizada para rellenar los píxeles reciéncreados que pueden aparecer después de una de las transformaciones anteriores.\n",
    "\n",
    "Estas son solo algunas de las opciones disponibles de transformación. Todas las restantes se pueden consultar en la página web de la API preprocessing de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    " \n",
    "uploaded=files.upload()\n",
    "for fn in uploaded.keys():\n",
    "    path='/content/' + fn\n",
    "    img=image.load_img(path)\n",
    "    data = img_to_array(img)\n",
    "    samples = expand_dims(data, 0)\n",
    "  \n",
    "    # example of \"rotation_range\"\n",
    "    datagen = ImageDataGenerator(rotation_range=45)\n",
    "\n",
    "    it = datagen.flow(samples, batch_size=1)\n",
    "    for i in range(6):\n",
    "        pyplot.subplot(230 + 1 + i)\n",
    "        batch = it.next()\n",
    "        image = batch[0].astype('uint8')\n",
    "        pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cómo se han generado diferentes imágenes aleatoriamente a partir de la imagen original y en base al argumento rotation_range. Se puede probar por su cuenta otros argumentos usando este código como base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/marcoteran/deeplearningmodule/raw/main/06_dataaugmentationandtransferlearning/data/cats_and_dogs_small.zip\n",
    "!unzip cats_and_dogs_small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'cats_and_dogs_small'\n",
    "\n",
    "train_dir =      os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir =       os.path.join(base_dir, 'test')\n",
    "\n",
    "# Directorio con las imagenes de training \n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directorio con las imagenes de validation\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Directorio con las imagenes de test\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training cat images :', len(os.listdir(train_cats_dir ) ))\n",
    "print('total training dog images :', len(os.listdir(train_dogs_dir ) ))\n",
    "\n",
    "print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\n",
    "print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))\n",
    "\n",
    "print('total test cat images :', len(os.listdir( test_cats_dir ) ))\n",
    "print('total test dog images :', len(os.listdir( test_dogs_dir ) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aumentación de los datos\n",
    "\n",
    "Es importante resaltar que el aumento de datos de imagen generalmente solo se aplica al conjunto de datos de entrenamiento, y no al conjunto de datos de validación o prueba. Esto es diferente de la preparación de datos, como el cambio de tamaño de la imagen y la escala de píxeles, que sí se aplica a todos. Teniendo en cuenta esto, los generadores para nuestro caso de estudio se pueden especificar de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n",
    "\n",
    "\n",
    "test_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo CNN con DA: Modelo CNN con *Data Augmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de una red convolucional de más capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDA = Sequential()\n",
    "modelDA.add(Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "modelDA.add(MaxPooling2D(2, 2))\n",
    "modelDA.add(Conv2D(64, (3,3), activation='relu'))\n",
    "modelDA.add(MaxPooling2D(2,2))\n",
    "modelDA.add(Conv2D(128, (3,3), activation='relu'))\n",
    "modelDA.add(MaxPooling2D(2,2))\n",
    "modelDA.add(Conv2D(128, (3,3), activation='relu'))\n",
    "modelDA.add(MaxPooling2D(2,2))\n",
    "modelDA.add(Flatten())\n",
    "modelDA.add(Dense(512, activation='relu'))\n",
    "modelDA.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar la estructura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDA.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red\n",
    "\n",
    "Ahora que ya se ha definido la estructura de red, el optimizador, learning rate y metricas ya se puede entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "historyDA = modelDA.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch= steps_per_epoch,\n",
    "    epochs= 100,\n",
    "    validation_data= validation_generator,\n",
    "    validation_steps= validation_steps,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la red\n",
    "\n",
    "Para ver si la red ha aprendido a clasificar bien los números manuscritos hay que comprobar la precisión que obtiene en el conjunto de datos de test. Para este conjunto no ha sido entrenada la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (steps_per_epoch)\n",
    "print (validation_steps)\n",
    "test_lost, test_acc= modelDA.evaluate(test_generator)\n",
    "print (\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc      = historyDA.history['acc' ]\n",
    "val_acc  = historyDA.history['val_acc']\n",
    "loss     = historyDA.history['loss' ]\n",
    "val_loss = historyDA.history['val_loss']\n",
    "\n",
    "epochs    = range(1,len(acc)+1,1) # obtener número de epochs\n",
    "\n",
    "plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
    "plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     loss, 'r--' )\n",
    "plt.plot  ( epochs, val_loss ,  'b' )\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, en esta sección hemos examinado esta técnica realmente útil que la API Keras ofrece para simular efectivamente un conjunto de datos más grande para entrenar la red neuronal y poder reducir así el problema de sobreentrenamiento.\n",
    "Aun así, las entradas que ve la red neuronal todavía están muy correlacionadas, ya que provienen de una pequeña cantidad de imágenes originales: no puede producir nueva información, solo puede mezclar la información existente. Como tal, esto puede no ser suficiente para deshacerse por completo del overfitting en algunos casos. Para seguir luchando en la mitigación del sobreentrenamiento se pueden añadir técnicas como la regularización o Dropout, que hemos comentado anteriormente. Pero incluso así, a veces, debido a no tener más datos, no es suficiente para obtener mejores modelos. Para estos casos aún nos queda otra oportunidad, que presentamos en la siguiente sección: usar modelos preentrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Se evidenció cómo aminorar el efecto de un sobreajuste de un modelo con una técnica muy útil para imágenes, como es Data Augmentation. Pero, en realidad, nos encontramos limitados en cuanto a descubrir características de los datos, puesto que si los datos de entrenamiento son muy pocos, al hacer transformaciones con la técnica de Data Augmentation parte de las características de las nuevas imágenes son repeticiones de las anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepto de Transfer Learning\n",
    "\n",
    "Transfer Learning es una de las técnicas centrales actualmente en Deep Learning. Su interés radica en que, en lugar de necesitar entrenar una red neuronal desde cero, lo cual implica disponer de una gran cantidad de datos y de mucho tiempo (días o semanas) de computación para entrenar, lo hacemos desde una red preentrenada.\n",
    "\n",
    "Esta técnica nos permite descargar un modelo de código abierto que alguien ya ha entrenado previamente en un gran conjunto de datos y usar sus parámetros (miles o millones) como punto de partida para, posteriormente, continuar entrenando el modelo con el conjunto de datos (más pequeño) que tengamos para una tarea determinada.\n",
    "\n",
    "Si el conjunto de datos original con el que se entrenó la red neuronal preentrenada es suficientemente grande y general, entonces la jerarquía espacial de las características (features) aprendidas por la red preentrenada permite al modelo preentrenado actuar como un modelo genérico del mundo visual y, por lo tanto, sus características pueden resultar útiles para muchos problemas diferentes de visión por computadora, a pesar de que estos nuevos problemas pueden involucrar clases completamente diferentes a las de la tarea original\n",
    "\n",
    "Recordaremos que en una red neuronal convolucional cada capa va aprendiendo diferentes niveles de abstracción, siendo las primeras capas las encargadas de aprender características más genéricas. Estas primeras capas son las que podemos volver a usar fácilmente, puesto que las características aprendidas son aplicables a otros problemas.\n",
    "\n",
    "Esta «portabilidad» de las características aprendidas a través de diferentes problemas es una de las virtudes clave del Transfer Learning. Específicamente, en el caso de la visión por computador, muchos modelos previamente entrenados (muchos entrenados en el conjunto de datos ImageNet ahora están disponibles públicamente para su descarga y se pueden usar para crear potentes modelos de visión con muy pocos datos.\n",
    "\n",
    "Hay dos formas de utilizar una red preentrenada, que presentamos a continuación: Feature Extraction y Fine-Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "Feature Extraction consiste en utilizar los parámetros aprendidos por una red preentrenada para extraer características (features) interesantes de nuevos datos.\n",
    "Estas características obtenidas de los nuevos datos se procesan a través de un nuevo clasificador, que se entrena desde cero.\n",
    "\n",
    "Las ConvNet utilizadas para clasificar imágenes se componían de dos partes: una serie de capas de convoluciones y pooling, y un clasificador formado habitualmente por una o varias capas densas.\n",
    "\n",
    "La primera parte se llama base convolucional (convolutional base) del modelo. En el caso de las ConvNet, la extracción de características consiste en tomar la base convolucional de una red previamente entrenada, ejecutar los nuevos datos a través de ella y entrenar a un nuevo clasificador en la parte de la salida.\n",
    "\n",
    "En la Figura 11.4 se muestra de forma esquemática esta idea. A la izquierda se muestra una ConvNet resaltando sus dos partes, la compuesta por las capas convolucionales y de pooling, y el clasificador final. En la figura del medio resaltamos que de esta ConvNet de base desechamos las capas finales de clasificación y nos quedamos con la primera parte, tanto con su estructura de capas como con los valores de los parámetros (pesos y sesgos de sus neuronas), que llamamos base convolucional. Finalmente, en la figura de la derecha se representa la estructura de la ConvNet que usaremos para clasificar nuestros nuevos datos. A la base convolucional que ya se encuentra entrenada le añadimos las capas finales que se requieran para hacer el clasificador a la medida del problema que estamos tratando. Recordemos que este nuevo clasificador sí que requiere entrenamiento.\n",
    "\n",
    "Representación esquemática de las redes neuronales preentrenadas usadas en la técnica de Feature Extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta muy útil reutilizar la base convolucional porque las características aprendidas por la red preeentrenada de donde se ha extraído son mapas de características de conceptos genéricos sobre una imagen, lo que en general resulta «portable» a otros problemas del mismo ámbito. En general no se reutiliza el clasificador entrenado, ya que las representaciones aprendidas por el clasificador serán necesariamente específicas del conjunto de clases en las que se formó el modelo; solo contendrán información sobre la probabilidad de presencia de esta o aquella clase en la imagen completa.\n",
    "\n",
    "Además, las representaciones encontradas en capas densamente conectadas ya no mantienen información sobre dónde se encuentran los objetos en la imagen de entrada porque estas capas eliminan la noción de espacio, a diferencia de las capas convolucionales\n",
    "\n",
    "Lo más interesante para nosotros ahora es que la API de Keras nos permite aplicar esta técnica de una manera muy fácil y con pocas líneas de código.\n",
    "Keras permite descargar un modelo y luego configurar cómo este debe ser entrenado, indicando qué capas son entrenables (Trainable layers) y qué capas no (Frozen layers).\n",
    "\n",
    "En general se requieren unas cuantas iteraciones de prueba y error para descubrir la combinación correcta. Concretamente en el caso de visión por computador, muchos modelos preentrenados con ImageNet se encuentran disponibles en la mayoría de librerías de desarrollo de Deep Learning, como es el caso de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En concreto en la página de modelos preentrenados ``tf.keras.applications172`` podemos encontrar disponibles los siguientes modelos para clasificación de imágenes entrenados con ImageNet:\n",
    "* Xception\n",
    "* VGG16\n",
    "* VGG19\n",
    "* ResNet50\n",
    "* InceptionV3\n",
    "* InceptionResNetV2\n",
    "* MobileNet\n",
    "* MobileNetV2\n",
    "* DenseNet\n",
    "* NASNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  VGG16: Modelo con *Feature Extraction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usará la red neuronal VGG16, que tiene una arquitectura convolucional como las que hemos comentado en los capítulos previos.\n",
    "La red neuronal VGG16 se ha entrenado previamente en un conjunto de datos de ImageNet, que recordemos que tiene 1.4 millones de imágenes en 1000 clases diferentes.\n",
    "ImageNet contiene muchas clases de animales, incluidas diferentes especies de gatos y perros, por lo que podemos esperar un buen rendimiento en el problema de clasificación de perros contra gatos.\n",
    "El modelo VGG16 es una red de 16 capas propuesta por Karen Simonyan y Andrew Zisserman en su artículo «Very Deep Convolutional Networks for Large-Scale Image Recognition»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo VGG16 podemos importarlo desde el módulo ``keras.applications``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A este constructor de la red VGG16 se le pasan tres argumentos.\n",
    "1. La forma de los tensores de imágenes que alimentarán a la red (es un argumento opcional).\n",
    "2. El argumento ``include_top`` donde se indica si se debe incluir (o no) el clasificador en la última capa de la red. \n",
    "    * Este caso, esta capa corresponde a la capa que clasifica las 1000 clases de ImageNet. Debido a que tenemos la intención de usar nuestro propio clasificador (que clasifica solo dos clases: gato y perro) no necesitamos incluirla.\n",
    "3. El último argumento, ``weights``, que indica de dónde se obtiene la información para iniciar los pesos de los parámetros de la red (en nuestro caso usaremos ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = VGG16(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método ``summary()`` podemos saber el detalle de la arquitectura de la base convolucional VGG16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si comparamos con la red neuronal VGG16 completa, se puede comprobar que no existen las dos capas finales fully-connected de 4096 neuronas ni la de 1000 neuronas (cada una de estas neuronas representa una de las categorías de imágenes de ImageNet), las cuales no incluten con el valor **``False``** del argumento ``include_top``\n",
    "\n",
    "No se necesitan las últimas capas (que son el clasificador de VGG16) porque se crearán unas propias para construir un clasificador y predecir si las imágenes serán un perro o un gato a partir del último feature map de forma y tamaño (4, 4, 512) que nos devuelve la base convolucional VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante: Antes de entrenar el modelo es necesario indicar cual de las capas de la base convolucional no deben ser entrenadas, lo que se denomina «congelar» capas (Freeze layers).\n",
    "\n",
    "Congelar una capa o un conjunto de capas significa evitar que sus pesos se actualicen durante el entrenamiento.\n",
    "* Si no se hiciera esto, los valores que fueron previamente aprendidos por la base convolucional serían modificados durante el entrenamiento, efecto que no se busca.\n",
    "* En Keras, congelar una capa se realiza estableciendo su atributo trainable a False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Keras los modelos los podemos considerar como capas y, por tanto, podemos agregar un modelo (como pre_trained_model) a un modelo secuencial al igual que agregaríamos una capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFE = Sequential()\n",
    "modelFE.add(pre_trained_model)\n",
    "modelFE.add(Flatten())\n",
    "modelFE.add(Dense(256, activation='relu'))\n",
    "modelFE.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así es como el método summary() presenta la red neuronal que se acaba de construir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el preprocesado de **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n",
    "\n",
    "test_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compila red utilizando los mismos parametros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "modelFE.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comienza a entrenar el modelo con el método ``fit()``, con la misma configuración de Data Augmentation que utilizamos en la sección anterior.\n",
    "\n",
    "Pero no es necesariamente siempre la mejor opción; la mejor combinación de técnicas depende del tipo y cantidad de datos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "historyFE = modelFE.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = steps_per_epoch,\n",
    "            epochs = 100,\n",
    "            validation_steps = validation_steps,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar la precisión con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lost, test_acc= modelFE.evaluate(test_generator)\n",
    "print (\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc      = historyFE.history['acc']\n",
    "val_acc  = historyFE.history[ 'val_acc']\n",
    "loss     = historyFE.history['loss']\n",
    "val_loss = historyFE.history['val_loss']\n",
    "\n",
    "epochs    = range(1,len(acc)+1,1) # obtener número de epochs\n",
    "\n",
    "plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
    "plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "#plt.ylim(0,1)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     loss, 'r--' )\n",
    "plt.plot  ( epochs, val_loss ,  'b' )\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "#plt.ylim(0,1)\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnica ampliamente utilizada en la reutilización de modelos, complementaria a la Feature Extraction.\n",
    "Consiste en hacer un ajuste más fino y entrenar también algunas de las capas finales de la base convolucional del modelo usado para la extracción de características (que hasta ahora se mantenía congelada), y entrenar conjuntamente tanto la parte agregada del clasificador como estas capas. Esto se llama Fine-Tuning en nuestro entorno porque se trata de un «ajuste fino» de las representaciones más abstractas del modelo que se está reutilizando como base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que el nivel de generalización y, por lo tanto, de reutilización de las representaciones extraídas por capas de convolución específicas depende de la posición de la capa en el modelo.\n",
    "* Las primeras capas aprenden características generales y, después, gradualmente en capas sucesivas se van aprendiendo características más concretas del dominio de problema que estamos tratando.\n",
    "* Las capas del modelo que están más próximas a la capa de entrada de datos extraen mapas de características locales altamente genéricas, mientras que las capas que están más cerca del clasificador final extraen conceptos más abstractos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos fijamos en el nombre que se le asigna a las capas en la base convolucional VGG16, vemos que se compone de 5 bloques: block1, block2, block3, block4, block5.\n",
    "\n",
    "Para mostrar la técnica de Fine-Tuning se entrenará el block5 compuesto por tres capas convolucionales y una de pooling (block5_conv1, block5_conv2 y block5_conv3 serán ahora entrenables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 : Modelo con *Fine Tuning*\n",
    "\n",
    "El código en Keras que permite especificar este comportamiento en la fase de entrenamiento que acabamos de describir puede ser el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "pre_trained_model = VGG16(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = 'imagenet')\n",
    "\n",
    "pre_trained_model.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable: \n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos igual que antes la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = Sequential()\n",
    "modelFT.add(pre_trained_model)\n",
    "modelFT.add(Flatten())\n",
    "modelFT.add(Dense(256, activation='relu'))\n",
    "modelFT.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el pre_trained_model tendrá más capas a entrenar, como podemos ver con la salida del método summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilación y entrenamiento de la red\n",
    "\n",
    "Se usarán los mismos hiperparámetros (optimizador RMSProp con learning rate de 1e-4), pero es importante dejar claro, para aquellos que quieran profundizar más en el tema, que estos hiperparámetros juegan un papel fundamental.\n",
    "* En general es una buena práctica usar un learning rate muy pequeño para limitar la magnitud de las modificaciones que se realizan en las tres capas del block5 que está ajustando.\n",
    "* Los learning rate que son demasiado grandes pueden dañar los pesos previos que venían de la red preentrenada, ya que mantenían información importante para representar a las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "modelFT.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación del conjunto de datos aumentados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "validation_generator =  validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n",
    "\n",
    "\n",
    "test_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "historyFT = modelFT.fit(\n",
    "    train_generator,\n",
    "    validation_data = validation_generator,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs = 100,\n",
    "    validation_steps = validation_steps,\n",
    "    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que en los anteriores modelos, se verifica gráficamente cómo evoluciona el entrenamiento en las gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc      = historyFT.history['acc']\n",
    "val_acc  = historyFT.history['val_acc']\n",
    "loss     = historyFT.history['loss']\n",
    "val_loss = historyFT.history['val_loss']\n",
    "\n",
    "epochs    = range(1,len(acc)+1,1) # obtener número de epochs\n",
    "\n",
    "plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
    "plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "#plt.ylim(0,1)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     loss, 'r--' )\n",
    "plt.plot  ( epochs, val_loss ,  'b' )\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos de pruebapara confirmar la mejora observada ya en el historial de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lost, test_acc= modelFT.evaluate(test_generator)\n",
    "print (\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accDA      = historyDA.history['acc']\n",
    "val_accDA  = historyDA.history['val_acc']\n",
    "\n",
    "accFE      = historyFE.history['acc']\n",
    "val_accFE  = historyFE.history['val_acc']\n",
    "\n",
    "accFT      = historyFT.history['acc']\n",
    "val_accFT  = historyFT.history['val_acc']\n",
    "\n",
    "epochs    = range(1,len(accDA)+1,1) \n",
    "\n",
    "plt.figure(figsize=(10,18))\n",
    "\n",
    "plt.plot(epochs, accFT,'k', label='Fine Tuning - Training acc')\n",
    "plt.plot(epochs, val_accFT,'b', label='Fine Tuning - Validation acc')\n",
    "\n",
    "plt.plot(epochs, accFE, 'r--', label='Feature Extraction - Training acc')\n",
    "plt.plot(epochs, val_accFE,  'm--', label='Feature Extraction - Validation acc')\n",
    "\n",
    "plt.plot(epochs, accDA, 'g:', label='Data Augmentation - Training acc')\n",
    "plt.plot(epochs, val_accDA,  'c:', label='Data Augmentation - Validation acc')\n",
    "\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.ylim(0.5,1)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con fotografías propias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "uploaded=files.upload()\n",
    "file=list(uploaded.keys())[0]\n",
    "\n",
    "path='/content/' + file\n",
    "img=image.load_img(path, target_size=(150, 150))\n",
    "\n",
    "x=image.img_to_array(img)\n",
    "image=np.expand_dims(x, axis=0)  \n",
    "\n",
    "classes = modelFT.predict(image)\n",
    "print(classes)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "if classes>0: print( fn + \" es un PERRO\")\n",
    "else: print( fn + \" es un GATO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
