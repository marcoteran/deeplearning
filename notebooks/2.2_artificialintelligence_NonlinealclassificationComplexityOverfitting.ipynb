{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17TzctyipNby"
   },
   "source": [
    "<!--NAVIGATION-->\n",
    "<a href=\"https://colab.research.google.com/github/marcoteran/machinelearning/blob/master/notebooks/01_machinelearning/03_artificialintelligence_nonlinealclassification_complexity_overfitting.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC0aAc7SpNb8"
   },
   "source": [
    "### Ejemplo de código\n",
    "# Sesión 02: Clasificación no lineal, complejidad y sobreajuste\n",
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mea_aZkQpNb9"
   },
   "source": [
    "**Name:** Marco Teran\n",
    "**E-mail:** marco.teran@usa.edu.co\n",
    "\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LT28CfchpNb9"
   },
   "source": [
    "Definimos primero unas librerías y funciones que vamos a usar a durante la sesión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GmturHnpNb_"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ez9_kSrKpNcA"
   },
   "outputs": [],
   "source": [
    "# Función para visualizar un conjunto de datos en 2D\n",
    "def plot_data(X, y):\n",
    "    y_unique = np.unique(y)\n",
    "    colors = pl.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[y == this_y]\n",
    "        pl.scatter(this_X[:, 0], this_X[:, 1],  c=color.reshape(1,-1),\n",
    "                    alpha=0.5, edgecolor='k',\n",
    "                    label=\"Class %s\" % this_y)\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Data\")\n",
    "    \n",
    "# Función para visualizar de la superficie de decisión de un clasificador\n",
    "def plot_decision_region(X, pred_fun):\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    min_x = min_x - (max_x - min_x) * 0.05\n",
    "    max_x = max_x + (max_x - min_x) * 0.05\n",
    "    min_y = min_y - (max_y - min_y) * 0.05\n",
    "    max_y = max_y + (max_y - min_y) * 0.05\n",
    "    x_vals = np.linspace(min_x, max_x, 100)\n",
    "    y_vals = np.linspace(min_y, max_y, 100)\n",
    "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "    grid_r, grid_c = XX.shape\n",
    "    ZZ = np.zeros((grid_r, grid_c))\n",
    "    for i in range(grid_r):\n",
    "        for j in range(grid_c):\n",
    "            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n",
    "    pl.contourf(XX, YY, ZZ, 100, cmap = pl.cm.coolwarm, vmin= -1, vmax=2)\n",
    "    pl.colorbar()\n",
    "    pl.xlabel(\"x\")\n",
    "    pl.ylabel(\"y\")\n",
    "    \n",
    "def gen_pred_fun(clf):\n",
    "    def pred_fun(x1, x2):\n",
    "        x = np.array([[x1, x2]])\n",
    "        return clf.predict(x)[0]\n",
    "    return pred_fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iwu-iagpNcA"
   },
   "source": [
    "# Complejidad\n",
    "\n",
    "Un modelo de clasificación puede ser tan complejo como para aprenderse de memoria el conjunto de entrenamiento. Esta complejidad está determinada por los parámetros internos del modelo. A continuación, observaremos como se comporta esta complejidad usando un modelo clasificación no lineal como lo es  **k-vecinos más cercanos** (*K-nearest neighbors* en inglés)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE99vZuhpNcB"
   },
   "source": [
    "## Definición del conjunto de datos\n",
    "\n",
    "Vamos a trabajar con un conjunto de datos artificial (conjunto de datos de juguete). El conjunto es creado usando la funcionalidad `make_moons` de Scikit-Learn [ver más](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html).\n",
    "`make_moons` permite introducir algo de ruido sobre las muestras creadas.\n",
    "\n",
    "`sklearn.datasets.make_moons(n_samples=100, *, shuffle=True, noise=None, random_state=None)`\n",
    "* **n_samples** Indica el número de muestras para cada grupo (clúster).\n",
    "* **n_features** El número de características de cada muestra (clústers).\n",
    "* **centros** El número de centros a generar o la posición fija del centro.\n",
    "* **noise** Desviación estándar del ruido gaussiano agregado a las muestras que pertenecen al mismo grupo\n",
    "* **shuffle** Mezcla las muestras\n",
    "* **random_state** Semilla del generador de muestras aleatorias. Este parámetro garantiza reproducibilidad del conjunto de datos.\n",
    "\n",
    "Salidas:\n",
    "* *X:* lista de las muestras generadas `[n_samples, n_features]`\n",
    "* *y:* lista de etiquetas `[n_samples]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UXFR2TapNcC"
   },
   "outputs": [],
   "source": [
    "X,y = make_moons(n_samples=600, noise=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEY1D3eApNcC",
    "outputId": "054b0ceb-21de-4c27-f850-a1725f37c523"
   },
   "outputs": [],
   "source": [
    "# Mo strar X ~ n_muestras x n_características\n",
    "# y ~ n_muestras\n",
    "# Primeras 5 muestras\n",
    "# Primeras 5 etiquetas\n",
    "\n",
    "print('Mostrar el tamaño de X:', X.shape)\n",
    "print('Mostrar el tamaño de y:', y.shape)\n",
    "\n",
    "print('Primeras 5 muestras\\n', X[:5,:])\n",
    "print('Primeras 5 etiquetas\\n', y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "kmJgR4HnpNcC",
    "outputId": "564d48a3-f408-403c-b6f8-c78de06aa112"
   },
   "outputs": [],
   "source": [
    "# Dibujar los datos\n",
    "pl.figure(figsize=(10,6))\n",
    "plot_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cseNt-N7pNcD"
   },
   "source": [
    "Observamos que es dificil establecer una separación lineal como en regresión logística. Por lo tanto es necesario usar un modelo de clasificación no lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqtb-ojGpNcD"
   },
   "source": [
    "# Algoritmo: K-vecinos más cercanos\n",
    "\n",
    "La clasificación basada en vecinos es un tipo de aprendizaje basado en ejemplos. El modelo almacena los ejemplos vistos durante entrenamiento y clasifica un elemento no visto, usando una simple regla de votación por mayoría. Si se ubica un **punto** en el espacio de características, se le asigna como clase el valor de la clase que tenga la mayor cantidad de ejemplos en la vecindad del punto. Este ejemplo lo podemos ver ilustrado en la imagen:\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/artificialintelligence/raw/master/notebooks/01_machinelearnig/figures/knn.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDBfUrxppNcE"
   },
   "source": [
    "Scikit-Learn provee una implementación del algoritmo conocida como `KNeighborsClassifier`. `KNeighborsClassifier` tiene un parámetro $n\\_neighbors$ o $k$, dónde $k$ es un entero definido por el usuario que determina cuantos vecinos evalua para determinar la clase de una instancia nunca antes vista. La elección de este parámetro es definida totalmente por la naturaleza de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-XTxcpHpNcE"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiSzL7UgpNcE"
   },
   "source": [
    "La librería te ofrece varios parámetros que puedes utilizar para configurar el algoritmo y algunos de ellos son muy útiles para mejorar el modelo que se este construyendo.\n",
    "\n",
    "* El primer parámetro, por su puesto debe ser el del número de vecinos o $k$, acá es donde defines este valor, a este parámetro se le conoce acá como `n_neighbors` (por defecto es $5$). Observaremos que dependiendo del valor de vecinos más cercanos, conseguimos diferentes funciones de ajuste, unas más suaves que otras. Vamos a evaluar el efecto del parámetro $k$ en la complejidad del modelo.\n",
    "* Otro parámetro importante es definir la distancia que se utilizará para verificar los vecinos del dato que se está buscando predecir. Para configurar esto en el algoritmo se debe definir dos variables dentro del algoritmo, la primera es `p` y la segunda es `metric`:\n",
    "    - `p` Es la función que computa la distancia, podemos elegir distintas, Euclidean con P=2, Manhatan con P=1, Mikowski cualquier otro valor.\n",
    "    - `metric` Variar distancia Mikowski a otras más complejas\n",
    "* weights: La ponderación de los votos de cada punto, puede ser:\n",
    "    - uniforme: todos los puntos valen lo mismo.\n",
    "    - distance: los votos de los puntos más cercanos tienen más valor\n",
    "* algorithm: controla el algoritmo que computa las distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWAdlJu0pNcF"
   },
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q08Bv_ykpNcF"
   },
   "source": [
    "Vamos a extraer un porcentaje al azar del conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4m8RsRXpNcF"
   },
   "outputs": [],
   "source": [
    "# X_reduced, y_reduced al 50% random\n",
    "idx=np.random.choice(len(X), int(len(X)*0.5), replace=False)\n",
    "X_reduced=X[idx]\n",
    "y_reduced=y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXP8FnK9pNcG"
   },
   "source": [
    "Entrenamos un modelo `knn` llamando la función `fit()` sobre el conjunto de datos reducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aM6M6cMEpNcG",
    "outputId": "4217e61e-2a57-4f39-96c1-38fda895c0b7"
   },
   "outputs": [],
   "source": [
    "knn.fit(X_reduced, y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "TGM9KR3SpNcG",
    "outputId": "d65da692-09ce-4193-db31-59e9a991527b"
   },
   "outputs": [],
   "source": [
    "# Dibujar la superficie de decición\n",
    "pl.figure(figsize=(10,6))\n",
    "plot_decision_region(X_reduced,gen_pred_fun(knn))\n",
    "plot_data(X_reduced, y_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZPrEsmopNcG",
    "outputId": "70fa5a0c-9236-4eef-da93-939f67643dfd"
   },
   "outputs": [],
   "source": [
    "# Mostrar el error\n",
    "print(knn.score(X_reduced, y_reduced))\n",
    "print('Error: {}'.format(1-knn.score(X_reduced, y_reduced)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5p0w3ICmpNcG"
   },
   "source": [
    "**¿Tiene sentido que el valor del error?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPdyZNPXpNcH"
   },
   "source": [
    "Ahora agreguemos los datos que descartamos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nBQl0w2pNcH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X_complement, y_complement\n",
    "idx_c = [i for i in range(len(X)) if i not in idx]\n",
    "\n",
    "X_complement=X[idx_c]\n",
    "y_complement=y[idx_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "u0625BtApNcH",
    "outputId": "0931d5d4-4d04-449c-ecec-e8c613c69ac7"
   },
   "outputs": [],
   "source": [
    "# Dibujemos la superficie de decisión\n",
    "pl.figure(figsize=(10,6))\n",
    "plot_decision_region(X_complement,gen_pred_fun(knn))\n",
    "plot_data(X_complement, y_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "leCD8RzvpNcH",
    "outputId": "e9f180a3-648c-4018-854b-f489f0d91fea"
   },
   "outputs": [],
   "source": [
    "# Mostrar el error\n",
    "print(knn.score(X_complement, y_complement))\n",
    "print('Error: {}'.format(1-knn.score(X_complement, y_complement)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPx6tYn9pNcI"
   },
   "source": [
    "Podemos observar que cuando el número de vecinos es $1$, el modelo se ajusta demasiado al ruído de los datos de entrada, por lo tanto sufre de **sobreajuste**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTOYCE25pNcI"
   },
   "source": [
    "# Error de entrenamiento y generalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxrAkJR6pNcI"
   },
   "source": [
    "Un modelo de aprendizaje de máquina tiene como objetivo principal hacer predicciones de manera acertada sobre ejemplos nunca antes vistos por el modelo. Esto se conoce como error de generalización. Para poder medir el error de generalización, dividimos el conjunto de datos en dos particiones: \n",
    "\n",
    "* **Entrenamiento**: Se usará para entrenar el modelo.\n",
    "* **Prueba**: Se usará para medir el error de generalización.\n",
    "\n",
    "En la siguiente imagen encontramos una ilustración de cómo se hace un particionamiento en entrenamiento y prueba.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/artificialintelligence/raw/master/notebooks/01_machinelearnig/figures/train_test_split.svg\" width=\"50%\">\n",
    "\n",
    "Una de las prácticas recomendadas, es particionar los datos $70\\%$ para entrenamiento y $30\\%$ para prueba. Cuando el número de muestras es muy grande ($\\ge 70K$), podemos reducir el porcentaje de muestras para prueba, a $90-10\\%$. Sin embargo, deben hacerse unas aclaraciones sobre la generalización:\n",
    "\n",
    "* El conjunto de prueba debe ser una muestra representativa del conjunto de datos. El muestreo de ejemplos debe hacerse de forma independiente e idénticamente aleatoria de una distribución. Esto quiere decir, que el muestreo de un ejemplo no está influenciado por el muestreo de otro.\n",
    "* La distribución es estacionaria. Es decir no cambia a lo largo del conjunto de datos.\n",
    "* Los ejemplos son muestreados desde particiones de la misma distribución. Es decir, no se deben crear nuevas características en la partición de prueba.\n",
    "\n",
    "Adicionalmente, debemos tener en cuenta que se conserve la distribución de las etiquetas de los datos tanto en entrenamiento como en prueba (estratificación). En la siguiente sesión se va a estudiar en más detalle los efectos de hacer una partición estratificada. Scikit-Learn nos permite particionar un conjunto de datos en entrenamiento y prueba. A continuación vamos a dividir el conjunto en $70\\%$ para entrenamiento y $30\\%$ para prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDfW9BzOpNcI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBuN7BX0pNcJ"
   },
   "source": [
    "#### Parámetros:\n",
    "\n",
    "* `test_size`: Tamaño de la partición de prueba\n",
    "* `random_state`: Semilla del generador de números pseudoaleatorios. Este parámetro garantiza reproducibilidad del particionamiento.\n",
    "* `stratify`: Si se estratifican los datos con respecto a `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hwHbPyOpNcJ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                     test_size=0.3,\n",
    "                                                     stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0jHoqjFpNcK"
   },
   "source": [
    "Vamos a verificar el número de muestras de ambas particiones y la distribución de clases de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQyPpgoZpNcK",
    "outputId": "0e51d5d9-8b70-44a4-90ee-84332a7fbebc"
   },
   "outputs": [],
   "source": [
    "# Mostrar\n",
    "# Número de muestras en entrenamiento\n",
    "# Número de muestras en prueba\n",
    "# Número de características\n",
    "# Distribución de clases en entrenamiento\n",
    "# Distribución de clases en prueba\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])\n",
    "print(X_train.shape[1])\n",
    "\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJPWlIWfpNcL"
   },
   "source": [
    "Usamos la partición recién creada y analizamos un modelo entrenado con $k = 200$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smgemRd1pNcL",
    "outputId": "551822c9-647b-43f4-d6c0-2c7f774bd6d4"
   },
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=200)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "9-ANWIj_pNcL",
    "outputId": "b26286af-425b-4c0a-8623-66ee572c7cef"
   },
   "outputs": [],
   "source": [
    "# Dibujar superficie de decición\n",
    "pl.figure(figsize=(10,6))\n",
    "plot_decision_region(X_train,gen_pred_fun(knn))\n",
    "plot_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MM8LpJjppNcM",
    "outputId": "275795f1-cff1-4463-9d0d-9ff07f314d66"
   },
   "outputs": [],
   "source": [
    "# Mostrar el error de entrenamiento\n",
    "print('Error: {}'.format(1-knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44wHHgbQpNcM"
   },
   "source": [
    "Observamos que el error en entrenamiento es del $14\\%$. Además se evidencia que el modelo entrenado es ahora demasiado **simple** y no se puede ajustar la estructura de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzcxxvmTpNcM"
   },
   "source": [
    "Ahora medimos el error de generalización del modelo entrenado y visualizamos la clasificación de los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "tiawhJ0tpNcM",
    "outputId": "8817a2ba-9956-400a-91c7-7df8d3805425",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dibujar superficie de decición con los datos de prueba\n",
    "pl.figure(figsize=(10,6))\n",
    "plot_decision_region(X_test,gen_pred_fun(knn))\n",
    "plot_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKqYLDCdpNcM",
    "outputId": "37bdf0a1-1271-492b-ef7a-aa8d75a51887"
   },
   "outputs": [],
   "source": [
    "# Mostrar el error de generalización\n",
    "print('Error: {}'.format(1-knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oW2jt55pNcN"
   },
   "source": [
    "Podemos observar que cuando aumentamos el número de vecinos, nuestro modelo sufre de **subajuste**. La superficie de decisión se suaviza, pero no logra captar los detalles de los datos. Mientras el error de entrenamiento se acerca a $14\\%$, el error de generalización se acerca a $10\\%$.\n",
    "\n",
    "**¿Cómo estimar un buen número de $k$-vecinos más cercanos de manera que el modelo no sobreajuste ni subajuste los datos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYuZya_QpNcN"
   },
   "source": [
    "# Evaluación de la complejidad\n",
    "\n",
    "Un modelo de aprendizaje de máquina puede ser tan complejo como para recordar las particularidades y el ruido del conjunto de entrenamiento (**sobreajuste**), así como puede ser demasiado flexible para no modelar la variabilidad de los datos (**subajuste**). El modelo debe garantizar un compromiso entre el sobreajuste y el subajuste, lo cual se logra evaluando la complejidad del modelo. Una forma de evaluar la complejidad es analizar el error de entrenamiento y generalización para diferentes modelos que varían en su complejidad. En el caso de `KNearestNeighbor`, la complejidad está determinada por el número de vecinos $k$. **Entre menor sea el número de vecinos, más complejo es el modelo.**\n",
    "\n",
    "A continuación exploramos un conjunto de valores $k$, con el objetivo de encontrar aquel modelo con el mejor compromiso entre error de entrenamiento y error de generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmD_Rj0-pNcN",
    "outputId": "fd68176d-bcdd-44a6-80f5-7b053b760b62"
   },
   "outputs": [],
   "source": [
    "k_values = list(range(1, 20))\n",
    "print(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KECyZGiwpNcO"
   },
   "source": [
    "Vamos a generar un nuevo conjunto de datos con $1000$ muestras y haremos una partición $70-30$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWQNUZalpNcO"
   },
   "outputs": [],
   "source": [
    "X,y = make_moons(n_samples=1000, noise=0.4, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                     test_size=0.3,\n",
    "                                                     stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l_Ty1ZIpNcP"
   },
   "source": [
    "Guardamos el error de entrenamiento y generalización con respecto al aumento de complejidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfiNWUSNpNcP"
   },
   "outputs": [],
   "source": [
    "train_error = []\n",
    "generalization_error = []\n",
    "\n",
    "# Utilizar un for\n",
    "\n",
    "for nn in k_values:\n",
    "  knn = KNeighborsClassifier(n_neighbors=nn)\n",
    "  knn.fit(X_train, y_train)\n",
    "  train_error.append(1-knn.score(X_train, y_train))\n",
    "  generalization_error.append(1-knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7qHKqVjpNcP"
   },
   "source": [
    "Visualizamos ambas curvas de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "YCrl0SMlpNcP",
    "outputId": "694f0e45-5918-44e2-ce22-6b02949877ec"
   },
   "outputs": [],
   "source": [
    "# Visualizar las curvas de aprendizaje\n",
    "pl.figure(figsize=(10,6))\n",
    "\n",
    "pl.plot(k_values, train_error, label='error de entrenamiento')\n",
    "pl.plot(k_values, generalization_error, label='error de generalización')\n",
    "pl.xticks(k_values)\n",
    "pl.xlabel(\"k-vecinos\")\n",
    "pl.ylabel(\"Error\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xgt6vk5wpNcP"
   },
   "source": [
    "Encontramos que el error de entrenamiento y generalización tiene su punto de balance mínimo con $k=13$. Observamos tambien que cuando el modelo es demasiado complejo ($k=1$), el error de generalización sube, así como el de entrenamiento cae a $0\\%$."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "03_artificialintelligence_nonlinealclassification_complexity_overfitting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
